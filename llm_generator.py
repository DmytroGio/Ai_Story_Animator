from openai import OpenAI
import os
from dotenv import load_dotenv
import json

load_dotenv()


class LLMGenerator:
    def __init__(self):
        self.client = OpenAI(
            base_url=os.getenv("LM_STUDIO_URL", "http://localhost:1234/v1"),
            api_key=os.getenv("LM_STUDIO_API_KEY", "lm-studio")
        )
        self.temperature = float(os.getenv("DEFAULT_TEMPERATURE", "0.8"))
        self.max_tokens = int(os.getenv("MAX_TOKENS", "1500"))

    def generate_story_scenes(self, user_idea, num_scenes=5):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ü–µ–Ω –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏

        Args:
            user_idea (str): –ò–¥–µ—è –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            num_scenes (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã
        """

        prompt = f"""You are a creative AI that generates visual story scenes for animation.

USER IDEA: {user_idea}

TASK: Create {num_scenes} distinct visual scenes that tell this story. Each scene should be described in detail for image generation.

IMPORTANT RULES:
1. Each scene description must be detailed and visual (describe colors, lighting, mood, composition)
2. Maintain consistency in characters and setting across scenes
3. Create a clear narrative progression from scene 1 to scene {num_scenes}
4. Each description should be 2-3 sentences long
5. Use cinematic and artistic language

FORMAT YOUR RESPONSE AS JSON:
{{
  "title": "Story Title",
  "scenes": [
    {{
      "scene_number": 1,
      "description": "Detailed visual description of scene 1...",
      "mood": "emotional mood (e.g., mysterious, hopeful, dramatic)"
    }},
    ...
  ]
}}

Generate the JSON response now:"""

        try:
            completion = self.client.chat.completions.create(
                model="local-model",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )

            response_text = completion.choices[0].message.content.strip()

            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            response_text = self._extract_json(response_text)

            # –ü–∞—Ä—Å–∏–Ω–≥ JSON
            story_data = json.loads(response_text)

            print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π: {story_data.get('title', 'Untitled')}")
            print(f"üìù –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω: {len(story_data.get('scenes', []))}")

            return story_data

        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{response_text}")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None

    def _extract_json(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ (—É–±–∏—Ä–∞–µ—Ç markdown —Ä–∞–∑–º–µ—Ç–∫—É)"""
        # –£–±–∏—Ä–∞–µ–º markdown code blocks
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]

        return text.strip()

    def generate_image_prompts(self, story_data, style="cinematic"):
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ü–µ–Ω—ã –≤ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è Stable Diffusion
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å—Ç–∏–ª–µ–π
        """
        from utils import StylePresets

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫—É —Å—Ç–∏–ª—è
        style_preset = StylePresets.get_style(style)
        style_suffix = style_preset['sd_suffix']

        prompts = []
        scenes = story_data.get("scenes", [])

        for scene in scenes:
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Stable Diffusion
            base_description = scene.get("description", "")
            mood = scene.get("mood", "")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            full_prompt = f"{base_description}, {mood} mood, {style_suffix}"

            prompts.append({
                "scene_number": scene.get("scene_number"),
                "prompt": full_prompt,
                "negative_prompt": "blurry, low quality, distorted, deformed, ugly, bad anatomy, watermark, signature, text"
            })

        return prompts


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üé¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤...\n")

    llm = LLMGenerator()

    # –¢–µ—Å—Ç–æ–≤–∞—è –∏–¥–µ—è
    test_idea = "A lonely robot discovers a small plant growing in a post-apocalyptic city"

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è
    story = llm.generate_story_scenes(test_idea, num_scenes=5)

    if story:
        print(f"\nüìñ –ù–∞–∑–≤–∞–Ω–∏–µ: {story.get('title')}\n")

        # –í—ã–≤–æ–¥ —Å—Ü–µ–Ω
        for scene in story.get("scenes", []):
            print(f"–°—Ü–µ–Ω–∞ {scene['scene_number']}:")
            print(f"  {scene['description']}")
            print(f"  –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {scene['mood']}\n")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        print("\nüé® –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è Stable Diffusion:\n")
        image_prompts = llm.generate_image_prompts(story, style="cinematic")

        for idx, prompt_data in enumerate(image_prompts, 1):
            print(f"{idx}. {prompt_data['prompt'][:100]}...")
            print()